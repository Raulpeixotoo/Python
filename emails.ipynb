{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8566ce08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c776fe65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_links_from_html(input_file):\n",
    "    try:\n",
    "        with open(input_file, 'r', encoding='utf-8') as file:\n",
    "            html_data = file.read()\n",
    "    except UnicodeDecodeError:\n",
    "        # Se a codificação utf-8 não funcionar, tente com latin-1\n",
    "        with open(input_file, 'r', encoding='latin-1') as file:\n",
    "            html_data = file.read()\n",
    "\n",
    "    # Usando expressão regular para encontrar os links\n",
    "    pattern = r'href=\"([^\"]*\\.com\\.br[^\"]*)\"'\n",
    "    links = re.findall(pattern, html_data)\n",
    "\n",
    "    return links\n",
    "\n",
    "# Caminho do arquivo .txt contendo os códigos HTML\n",
    "input_file_path = 'al.txt'\n",
    "\n",
    "# Extrair os links\n",
    "links = extract_links_from_html(input_file_path)\n",
    "\n",
    "# Criar uma lista para a tabela do Excel\n",
    "data = {'Links': links}\n",
    "\n",
    "# Criar um DataFrame a partir da lista de dados\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Salvar a tabela em um arquivo Excel\n",
    "output_excel_path = 'links_extraidos_al.xlsx'\n",
    "df.to_excel(output_excel_path, index=False)\n",
    "\n",
    "print(f'Os links foram extraídos e salvos em {output_excel_path}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdf7d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###separar os links dos alerts\n",
    "caminho_planilha = 'links_extraidosalerts.xlsx'\n",
    "df = pd.read_excel(caminho_planilha)\n",
    "\n",
    "# Função para remover URLs indesejados\n",
    "def remover_urls_indesejados(texto):\n",
    "    texto_sem_google = re.sub(r\"https://www\\.google\\.com(\\.br)?\", \"\", texto)\n",
    "    return texto_sem_google\n",
    "\n",
    "# Função para extrair e limpar os URLs\n",
    "def extrair_e_limpar_urls(texto):\n",
    "    padrao_url = r\"https://\\S+\"\n",
    "    urls_encontrados = re.findall(padrao_url, texto)\n",
    "    urls_limpados = [re.sub(r\"(&amp;|%).*\", \"\", url) for url in urls_encontrados]\n",
    "    return urls_limpados\n",
    "\n",
    "# Aplicar a função para remover os URLs indesejados na coluna \"Links\"\n",
    "df['Links'] = df['Links'].apply(remover_urls_indesejados)\n",
    "\n",
    "# Aplicar a função para cada célula da coluna \"Links\" para extrair e limpar os URLs\n",
    "df['Links'] = df['Links'].apply(extrair_e_limpar_urls)\n",
    "\n",
    "# Criar uma nova coluna com os URLs separados individualmente\n",
    "df['URLs Separados'] = df['Links'].apply(lambda x: ', '.join(x) if len(x) > 0 else None)\n",
    "\n",
    "# Salvar o DataFrame de volta na planilha, se desejar (substitua 'planilha_nova.xlsx' pelo nome desejado)\n",
    "df.to_excel('links_extraidosalerts.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8f913d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
